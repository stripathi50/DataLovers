---
title: "US Census Demographic Data"
author: "Data lovers"
date: "09 Nov 2021"
# date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: hide
    number_sections: false
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
---

```{r init, include=FALSE}
# some of common options (and the defaults) are: 
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right', 
library(ezids)
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
knitr::opts_chunk$set(warning = F, results = "hide", message = F)
options(scientific=T, digits = 3) 
# options(scipen=9, digits = 3) 
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times
```


### Chapter 1:Introduction.

Census is a very important matter, not just at the government level, but for individuals as well. The census population count decides how many congressional members each state will have for the following ten years, as well as how much federal funds localities will receive for roads, schools, housing, and social programs. 

Poverty is a complicated issue. There are numerous elements to it, as well as numerous reasons. The most common definition of poverty focuses on financial hardship. This definition defines poverty rates for towns and countries based on income inequality and financially established poverty lines and quantifies poverty by the amount of money a person makes.

Poverty becomes relative in this way. In the United States, the poverty line for a family of four is little over $26,000 a year. That amount of money is more than 36 times what a family of four living in absolute poverty in a low-income country is forced to subsist on each year.

Many families in the world's poorest countries must make do with less than $1.90 per day to cover their basic requirements. This sort of extreme poverty affects nearly 10% of the world's population.

Understanding poverty solely in terms of economic disparity and calculating relative poverty thresholds makes it impossible to see poverty as anything other than unemployment, bad living conditions, and a low income. Poverty, on the other hand, is a much broader concept.

A fair definition of poverty must take into account the many various aspects of poverty, such as hunger and a lack of shelter, illiteracy and lack of access to education, being sick and unable to see a doctor, and fearing for one's future.

By exploring this data and analyzing it we can come up with many insights, such as how the population varies across the states, which states that have the best transportation, how do income and poverty look like across US, employment/unemployment rates and so many questions that can be answered from these data. 

Therefore, our aim in this project is to analyze the US census of 2015 to answer our interesting question: 

What factors affect poverty in counties? 


### Chapter 2:Description of the Data.

•	Dataset that is used for our project is “US Census Demographic Data” taken from the common data source Kaggle (which is an online community of data scientists and machine learning practitioners.

Link: https://www.kaggle.com/muonneutrino/us-census-demographic-data?select=acs2015_county_data.csv

•	Dataset contains information about (US Census 2015) American Community Survey 5-year estimates. 

•	Number of variables in the dataset is 37.

•	Number of observations in the dataset is 3220.

•	To perform Exploratory Data Analysis, we primarily focus on the following aspects(variables) from the dataset:

* TotalPop (Total population for county).

*	Income. (Income in county).

*	Poverty (Poverty rate in county).

*	ChildPoverty. (Child poverty rate in county).

* Employed (Total employed for county).

*	Unemployment. (Unemployment rate for county).

* Production. (Rate of this job sector in county).

* WorkAtHome. (Work-at-home rate in county).

* PublicWork. (Public work rate in county).

* SelfEmployed. (Self-employed rate in county).





**This is our dataset before performing any cleansing or dropping columns: **

```{r step1, results='hold'}


# importing the dataset as Adata, and making sure the data type for the variables are set properly for categorical variables.**

Adata1 <- data.frame(read.csv("acs2015_county_data.csv",header = TRUE))

str(Adata1)

#summary(Adata1)

#  we don't need to change any variables type, all of them set properly.
# There are a lot of variables , we may drop some of them, like :
#Hispanic, White,	Black,	Native,	Asian	Pacific, IncomeErr,	IncomePerCap,	IncomePerCapErr


# Dropping columns as agreed.  

Adata <- data.frame (subset(Adata1, select = -c(Hispanic,White,Black, Native, Asian, Pacific,IncomeErr, IncomePerCap, IncomePerCapErr, Drive, Carpool, Transit, Walk, OtherTransp, MeanCommute)))

str(Adata)
#summary(Adata)
  

```



**And here is the summary of our dataset **
```{r summary, results='hold'}


summary(Adata)


```


### Chapter 3: Data Cleaning and Normality tests.

***Section 3.1: Data cleaning **

In this section of this chapter, we will prepare our dataset for EDA. So, we will perform the following steps:

1- Drop the unnecessary columns. 

2- Remove the outliers. 

3- Remove the Null values if exist.



To detect the outliers, we first polt it using Hitogram , then remove outliers, finally polt it again to check after removing the outliers. Same technique applied for all the 10 variables. 


***Cleaning the data for Income column **
```{r step2}

# After reading the data we need now to clean it to prepare for the analysis. 
# We started with "income", first we polte it to identify the outlier and then removing it. 
# Also , we removed the null values because it make error while do mathematics calculation. 
# Then we follow the same steps for the remaining columns that we will gonna use in this phase. 
# Currently our desired columns: TotalPop, Income, Poverty, ChildPoverty, Employed, Unemployment, Production, WorkAtHome,PublicWork, SelfEmployed

################################################################################


# First, lets take a look at the histogram for the income to detect the outliers 



hist(Adata$Income,
  xlab = "Income",
  main = "Histogram of Income",
  breaks = sqrt(nrow(Adata))
) # set number of bins




# # Now, we can extract the outliers from the incom using boxplot.stats()$out function.  
 income_out <- boxplot.stats(Adata$Income)$out
 income_out


# To count how many outliers in the income
 x <- data.frame(income_out)
x 
 nrow(x) # outliers numbers for income


 #Now, we will remove the outliers from our dataset and store the clean result in Adata2

  Adata2<- Adata[-which(Adata$Income %in% income_out),] # here we removed income outlier


 Adata2
 
 hist(Adata2$Income,
  xlab = "Income",
  main = "Histogram of Income",
  breaks = sqrt(nrow(Adata2))
) # set number of bins

 
# #Adata
# Adata2 


 # Now we will remove the naull values from the incmoe to allow for math calculations. 
 
 my.null <- data.frame (subset(Adata2,subset= is.na(Adata2$Income)))# To indicate the null values of income. 
my.null


Adata3 <- data.frame (subset(Adata2, subset= CensusId!= 48301 )) # To remove the record that contains null value

# Now we can calculate the max, mean , min .. etc of the income
max(Adata3$Income)
mean(Adata3$Income)
min(Adata3$Income)



```




**Cleaning the data for population column. **

```{r}

# same thing for population column. clean the data. 

# First, lets take a look at the histogram for the population to detect the outliers 



hist(Adata3$TotalPop,
  xlab = "TotalPop",
  main = "Histogram of Population",
  breaks = sqrt(nrow(Adata3))
) # set number of bins




# # Now, we can extract the outliers from the population using boxplot.stats()$out function.  
 pop_out <- boxplot.stats(Adata3$TotalPop)$out
 pop_out


# To count how many outliers in the population
 x2 <- data.frame(pop_out)
x2 
 nrow(x2) # outliers numbers 


 #Now, we will remove the outliers from our dataset and store the clean result in Adata4

  Adata4<- Adata3[-which(Adata3$TotalPop %in% pop_out),] # here we removed  outlier


 Adata4
 
 hist(Adata4$TotalPop,
  xlab = "TotalPop",
  main = "Histogram of Population",
  breaks = sqrt(nrow(Adata4))
) # set number of bins

 
# #Adata
# Adata2 


 # Now we will remove the naull values from the population to allow for math calculations. 
 
 my.null2 <- data.frame (subset(Adata4,subset= is.na(Adata4$TotalPop)))# To indicate the null values of Population 
my.null2  # No null values. 


# Now we can calculate the max and the mean .. etc of the population. 
max(Adata4$TotalPop)
mean(Adata4$TotalPop)
min(Adata4$TotalPop)



```



**Cleaning the data for Poverty column. **
```{r}


# same thing for poverty column. clean the data. 

# First, lets take a look at the histogram for the poverty to detect the outliers 



hist(Adata4$Poverty,
  xlab = "Poverty",
  main = "Histogram of Poverty",
  breaks = sqrt(nrow(Adata4))
) # set number of bins




# # Now, we can extract the outliers from the population using boxplot.stats()$out function.  
 Poverty_out <- boxplot.stats(Adata4$Poverty)$out
 Poverty_out


# To count how many outliers in the population
 x3 <- data.frame(Poverty_out)
x3 
 nrow(x3) # outliers numbers 


 #Now, we will remove the outliers from our dataset and store the clean result in Adata5

  Adata5<- Adata4[-which(Adata4$Poverty %in% Poverty_out),] # here we removed  outlier


 Adata5
 
 hist(Adata5$Poverty,
  xlab = "Poverty",
  main = "Histogram of Poverty",
  breaks = sqrt(nrow(Adata5))
) # set number of bins

 
 



 # No null values. 
 

# Now we can calculate the max and the mean .. etc of the population. 
max(Adata4$Poverty)
mean(Adata4$Poverty)
min (Adata4$Poverty)






```


**Cleaning the data for Child Poverty column. **

```{r}


# same thing for Child Poverty column. clean the data. 

# First, lets take a look at the histogram for the Child Poverty to detect the outliers 



hist(Adata5$ChildPoverty,
  xlab = "ChildPoverty",
  main = "Histogram of ChildPoverty",
  breaks = sqrt(nrow(Adata5))
) # set number of bins




# # Now, we can extract the outliers using boxplot.stats()$out function.  
 ChildPoverty_out <- boxplot.stats(Adata5$ChildPoverty)$out
 ChildPoverty_out


# To count how many outliers in the population
 x4 <- data.frame(ChildPoverty_out)
x4
 nrow(x4) # outliers numbers 


 #Now, we will remove the outliers from our dataset and store the clean result in Adata6

  Adata6<- Adata5[-which(Adata5$ChildPoverty %in% ChildPoverty_out),] # here we removed  outlier


 Adata6
 
 hist(Adata6$ChildPoverty,
  xlab = "ChildPoverty",
  main = "Histogram of Child Poverty",
  breaks = sqrt(nrow(Adata6))
) # set number of bins

 
 

 
 my.null3 <- data.frame (subset(Adata6,subset= is.na(Adata6$ChildPoverty)))# To indicate the null values
my.null3  
 

 Adata7 <- data.frame (subset(Adata6, subset= CensusId!= 15005 )) # To remove the record that contains null value



# Now we can calculate the max and the mean .. etc of the population. 
max(Adata7$ChildPoverty)
mean(Adata7$ChildPoverty)
min (Adata7$ChildPoverty)






```


**Cleaning the data for Employed column  ** 

```{r}

# same thing for Employed column. clean the data. 

# First, lets take a look at the histogram for the Employed to detect the outliers 



hist(Adata7$Employed,
  xlab = "Employed",
  main = "Histogram of Employed",
  breaks = sqrt(nrow(Adata7))
) # set number of bins




# # Now, we can extract the outliers using boxplot.stats()$out function.  
 Employed_out <- boxplot.stats(Adata7$Employed)$out
 Employed_out


# To count how many outliers in the population
 x5 <- data.frame(Employed_out)
x5
 nrow(x5) # outliers numbers 


 #Now, we will remove the outliers from our dataset and store the clean result in Adata8

  Adata8<- Adata7[-which(Adata7$Employed %in% Employed_out),] # here we removed outlier


 Adata8
 
 hist(Adata8$Employed,
  xlab = "Employed",
  main = "Histogram of Employed",
  breaks = sqrt(nrow(Adata8))
) # set number of bins

 
 
# No null values. 
 

# # Now we can calculate the max and the mean .. etc of the population. 
max(Adata8$Employed)
mean(Adata8$Employed)
min (Adata8$Employed)



```


**Cleaning the data for Unemployment column  ** 


```{r}


# same thing for Unemployment column. clean the data. 

# First, lets take a look at the histogram for the Unemployment to detect the outliers 



hist(Adata8$Unemployment,
  xlab = "Unemployment",
  main = "Histogram of Unemployment",
  breaks = sqrt(nrow(Adata8))
) # set number of bins




 # Now, we can extract the outliers using boxplot.stats()$out function.  
 Unemployment_out <- boxplot.stats(Adata8$Unemployment)$out
 Unemployment_out
# 
# 
#  To count how many outliers in the population
  x6 <- data.frame(Unemployment_out)
 x6
  nrow(x6) # outliers numbers 
# 
# 
 #Now, we will remove the outliers from our dataset and store the clean result in Adata9
# 
   Adata10<- Adata8[-which(Adata8$Unemploymen %in% Unemployment_out),] # here we removed outlier
# 
# 
 Adata10
#  
  hist(Adata10$Unemployment,
   xlab = "Unemployment",
   main = "Histogram of Unemployment",
   breaks = sqrt(nrow(Adata10))
) # set number of bins
  


# # No null values. 
 
# 
# # # Now we can calculate the max and the mean .. etc . 
 max(Adata10$Unemployment)
 mean(Adata10$Unemployment)
min (Adata10$Unemployment)
 



```


**Cleaning the data for Production column  ** 


```{r}


# same thing for Production column. clean the data. 

# First, lets take a look at the histogram for the Production to detect the outliers 



hist(Adata10$Production,
  xlab = "Production",
  main = "Histogram of Production",
  breaks = sqrt(nrow(Adata10))
) # set number of bins




 # Now, we can extract the outliers using boxplot.stats()$out function.  
 production_out <- boxplot.stats(Adata10$Production)$out
 production_out
# 
# 
#  To count how many outliers in the population
  x7 <- data.frame(production_out)
 x7
  nrow(x7) # outliers numbers 
# 
# 
 #Now, we will remove the outliers from our dataset and store the clean result in Adata11
# 
   Adata11<- Adata10[-which(Adata10$Production %in% production_out),] # here we removed outlier
# 
# 
 Adata11
#  
  hist(Adata11$Production,
   xlab = "Production",
   main = "Histogram of Production",
   breaks = sqrt(nrow(Adata11))
) # set number of bins
  


# # No null values. 
 
# 
# # # Now we can calculate the max and the mean .. etc . 
 max(Adata11$Production)
 mean(Adata11$Production)
min (Adata11$Production)
 






```

**Cleaning the data for WorkAtHome column  ** 

```{r}


# same thing for WorkAtHome column. clean the data. 

# First, lets take a look at the histogram for the WorkAtHome to detect the outliers 



hist(Adata11$WorkAtHome,
  xlab = "WorkAtHome",
  main = "Histogram of WorkAtHome",
  breaks = sqrt(nrow(Adata11))
) # set number of bins




 # Now, we can extract the outliers using boxplot.stats()$out function.  
 WorkAtHome_out <- boxplot.stats(Adata11$WorkAtHome)$out
 WorkAtHome_out
# 
# 
#  To count how many outliers in the population
  x8 <- data.frame(WorkAtHome_out)
 x8
  nrow(x8) # outliers numbers 
# 
# 
 #Now, we will remove the outliers from our dataset and store the clean result in Adata11
# 
   Adata12<- Adata11[-which(Adata11$WorkAtHome %in% WorkAtHome_out),] # here we removed outlier
# 
# 
 Adata12
#  
  hist(Adata12$WorkAtHome,
   xlab = "WorkAtHome",
   main = "Histogram of WorkAtHome",
   breaks = sqrt(nrow(Adata12))
) # set number of bins
  


# # No null values. 
 
# 
# # # Now we can calculate the max and the mean .. etc . 
 max(Adata12$WorkAtHome)
 mean(Adata12$WorkAtHome)
min (Adata12$WorkAtHome)
 






```

**Cleaning the data for PublicWork column  ** 


```{r}


# same thing for PublicWork column. clean the data. 

# First, lets take a look at the histogram for the PublicWork to detect the outliers 



hist(Adata12$PublicWork,
  xlab = "PublicWork",
  main = "Histogram of PublicWork",
  breaks = sqrt(nrow(Adata12))
) # set number of bins




 # Now, we can extract the outliers using boxplot.stats()$out function.  
 PublicWork_out <- boxplot.stats(Adata12$PublicWork)$out
 PublicWork_out
# 
# 
#  To count how many outliers in the population
  x9 <- data.frame(PublicWork_out)
 x9
  nrow(x9) # outliers numbers 
# 
# 
 #Now, we will remove the outliers from our dataset and store the clean result in Adata11
# 
   Adata13<- Adata12[-which(Adata12$PublicWork %in% PublicWork_out),] # here we removed outlier
# 
# 
 Adata13
#  
  hist(Adata13$PublicWork,
   xlab = "PublicWork",
   main = "Histogram of PublicWork",
   breaks = sqrt(nrow(Adata13))
) # set number of bins
  


# # No null values. 
 
# 
# # # Now we can calculate the max and the mean .. etc . 
 max(Adata13$PublicWork)
 mean(Adata13$PublicWork)
min (Adata13$PublicWork)
 



```


**Cleaning the data for SelfEmployed column  ** 


```{r}

# same thing for PublicWork column. clean the data. 

# First, lets take a look at the histogram for the PublicWork to detect the outliers 



hist(Adata13$SelfEmployed,
  xlab = "SelfEmployed",
  main = "Histogram of SelfEmployed",
  breaks = sqrt(nrow(Adata13))
) # set number of bins




 # Now, we can extract the outliers using boxplot.stats()$out function.  
 SelfEmployed_out <- boxplot.stats(Adata13$SelfEmployed)$out
 SelfEmployed_out
# 
# 
#  To count how many outliers in the population
  x10 <- data.frame(SelfEmployed_out)
 x10
  nrow(x10) # outliers numbers 
# 
# 
 #Now, we will remove the outliers from our dataset and store the clean result in Adata11
# 
   Adata14<- Adata13[-which(Adata13$SelfEmployed %in% SelfEmployed_out),] # here we removed outlier
# 
# 
 Adata14
#  
  hist(Adata14$SelfEmployed,
   xlab = "SelfEmployed",
   main = "Histogram of SelfEmployed",
   breaks = sqrt(nrow(Adata14))
) # set number of bins
  


# # No null values. 
 
# 
# # # Now we can calculate the max and the mean .. etc . 
 max(Adata14$SelfEmployed)
 mean(Adata14$SelfEmployed)
min (Adata14$SelfEmployed)





```



**Final dataset **

As we can see bellow, after performing the cleansing process, we removed 1,147 record which include 2 NA values and 1,145 outliers. Now we have 2073 obs across 22 variables, the data shrink, however we have now more accurate dataset that will help us perform reliable tests as well as more accurate results.   



```{r final dataset, results='hold'}

# This is the final data set:
Adata9 = Adata14

str(Adata9)

#summary(Adata9)

#########################




```


**Final Dataset Summary **
```{r final summary, results='hold'}

summary(Adata9)


```


**Standard deviation for the columns to check how the data spread out after cleansing process**

```{r SD, results='hold'}


# Standard deviation for the columns: 

sd(Adata9$Income)
sd(Adata9$TotalPop)
sd(Adata9$Poverty)
sd(Adata9$ChildPoverty)
sd(Adata9$Employed)
sd(Adata9$Unemployment)
sd(Adata9$Production)
sd(Adata9$WorkAtHome)
sd(Adata9$PublicWork)
sd(Adata9$SelfEmployed)

```



**Normality tests  ** 

**Section 3.2: Normality tests **

**The following graphs are the normality test for our desired columns.** 

In this section of this chapter, we will test the normality distribution of all our desired columns to prepare them for other tests. We used two graphs for each variable: QQ-plot using qqpot function and QQ-plot using qqnorme function.   



```{r}


library(ggplot2)



#This code enable us to use qqplot.data function (to draw a line)

qqplot.data <- function (vec) # argument: vector of numbers
{
  y <- quantile(vec[!is.na(vec)], c(0.25, 0.75))
  x <- qnorm(c(0.25, 0.75))
  slope <- diff(y)/diff(x)
  int <- y[1L] - slope * x[1L]
  d <- data.frame(resids = vec)
  ggplot(d, aes(sample = resids)) + stat_qq() + geom_abline(slope = slope, intercept = int)
  
}

# Histogram that use ggplot: 

# 1 Graph for income distribution:
g1 <- qqplot.data(Adata9$Income)+labs(title = "Income Distribution")
g1

# 2 Graph for population distribution
g2 <- qqplot.data(Adata9$TotalPop)+labs(title = "Population Distribution")
g2


# 3 Graph for Poverty distribution
g3 <- qqplot.data(Adata9$Poverty)+labs(title = "Poverty Distribution")
g3


# 4 Graph for child poverty distribution
g4 <- qqplot.data(Adata9$ChildPoverty)+labs(title = "Child Poverty Distribution")
g4


# 5 Graph for Employed distribution
g5 <- qqplot.data(Adata9$Employed)+labs(title = "Employed Distribution")
g5


# 6 Graph for unemployment distribution
g6 <- qqplot.data(Adata9$Unemployment)+labs(title = "Unemployment Distribution")
g6


# 7 Graph for Production distribution
g7 <- qqplot.data(Adata9$Production)+labs(title = "Production Distribution")
g7

# 8 Graph for Production distribution
g8 <- qqplot.data(Adata9$WorkAtHome)+labs(title = "WorkAtHome Distribution")
g8

# 9 Graph for PublicWork distribution
g9 <- qqplot.data(Adata9$PublicWork)+labs(title = "PublicWork Distribution")
g9

# 10 Graph for SelfEmployed distribution
g10 <- qqplot.data(Adata9$SelfEmployed)+labs(title = "SelfEmployed Distribution")
g10

###########################################



# Additional graphs for two variables only.  QQ-plot that use qqnorm

# 1 Graph for income
qqnorm(Adata9$Income,main = "Q-Q plot. Income Distribution") 

#2 Graph for population
 qqnorm(Adata9$TotalPop,main = "Q-Q plot. Population Distribution")

 
#3 Graph for Poverty
 qqnorm(Adata9$Poverty,main = "Q-Q plot. Poverty Distribution")

 
#4 Graph for child poverty
 qqnorm(Adata9$ChildPoverty,main = "Q-Q plot. Child Poverty Distribution")

 #5 Graph for Employed
 qqnorm(Adata9$Employed,main = "Q-Q plot. Employed Distribution")
 
#6 Graph for unemployment
 qqnorm(Adata9$Unemployment,main = "Q-Q plot. Unemlpyment Distribution")
 

 #7 Graph for Production
 qqnorm(Adata9$Production,main = "Q-Q plot. Production Distribution")
 
 
 #8 Graph for WorkAtHome
 qqnorm(Adata9$WorkAtHome,main = "Q-Q plot. WorkAtHome Distribution")
 
 
#9 Graph for PublicWork
 qqnorm(Adata9$PublicWork,main = "Q-Q plot. PublicWork Distribution")
 
 
 #10 Graph for SelfEmployed
 qqnorm(Adata9$SelfEmployed,main = "Q-Q plot. SelfEmployed Distribution")
 
 

```


**Our conclusion:**

**From these graphs, we noticed that the columns that use rates instead of total number are normally distributed like: income, poverty,child poverty, unemployment, Production,WorkAtHome,PublicWork, SelfEmployed.While the columns that use total numbers are not normally distributed like: Total population and Employed columns. ** 
**The columns that we need them for our tests are normally distributed, so we are good to go! **  


### Chapter 4: Graphs and relationship
**What factors affect poverty in counties?  ** 

Graphical or Realistic representation is another way of dissecting numerical information. A graphical representation may be a sort of chart through which factual information are spoken to within the frame of lines or bends drawn over the facilitated focuses plotted on its surface. Similarly, we have worked on different graphs to show different possible conditions and reason to show major reasons of increasing poverty.

We have started with showcasing the level of poverty in 50 states of America from which Texas has the maximum population to poverty ratio which is almost 8.69 % of total population in USA and least population to poverty ratio is in Rhode Island which is 0.01871068 % of total population.

```{r}


#7. What factors affect poverty in counties? 

loadPkg("ggplot2")
loadPkg("gridExtra")
loadPkg("ggcorrplot")
xkablesummary(Adata9)

# Poverty in different states 
State_fact<-as.factor(Adata9$State)
Check<-aggregate(x= Adata9$Poverty, by= list(Adata9$State),FUN= sum)
Check
sum(Check$x)
pie_labels <- paste0(Check$Group.1, " = ", round(100 * Check$x/sum(Check$x), 2), "%")
population_pie_Chart = pie(Check$x,labels = pie_labels, radius=1, main="Pie Chart Of Poverty In Different States Of USA", clockwise = TRUE)
library(ggplot2)

#factors affecting poverty 

#1. unemployement

Check2<-aggregate(x=Adata9$Unemployment, by= list(Adata9$State), FUN= sum)
Check2

#barplot(Check2$x, main = "State Vs Unemployement", names.arg = Check2$Group.1, xlab = "States", ylab = "Unemployement Scale", angle = 90, cey.axis = 1)
Unemployment_Bar_graph<-barplot(Check2$x,names.arg = Check2$Group.1, xlab = "States", ylab = "Unemployement Scale",  main = "State Vs Unemployement", las = 3)

#2. population and income

Check3<-aggregate(x=Adata9$TotalPop, by= list(Adata9$State), FUN= sum)
Check3


histPop <- ggplot(data=Check3, aes(x)) + 
  geom_histogram(breaks=seq(20000, 3000000, by = 100000), 
                 col="red", 
                 fill="#00aa22", 
                 alpha = .7) + # opacity
  labs(title="Population of the States") +
  labs(x="Population", y="Frequency") 

Check4<-aggregate(x=Adata9$Income, by= list(Adata9$State), FUN= sum)
Check4

histIncome <- ggplot(data=Check4, aes(x)) + 
  geom_histogram(breaks=seq(20000, 3000000, by = 100000), 
                 col="red", 
                 fill="#0000aa", 
                 alpha = .7) + # opacity
  labs(title="Income of the States") +
  labs(x="Income", y="Frequency")

grid.arrange(histPop, histIncome, ncol=2, nrow=1)


#3. Impact of unemployement, population and income on Poverty 
Income_pop <- ggplot(Adata9) +
    geom_point(aes(x = Income , y = TotalPop, size = 2 ), alpha = 0.7 , col = "red" )+labs(title = "Population vs Income")+labs(x="Income", y="Population" )

Unemployment_Pop <- ggplot(Adata9) +
    geom_point(aes(x = Unemployment , y = TotalPop, size = 2), alpha = 0.7, col = "red")+labs(title = "Population vs Unemployement")+labs(x="Unemployement", y="Population" )

Income_pop
Unemployment_Pop

#Correlation employed vs Income

library(ggcorrplot)

Check5 <- data.frame(Adata9$Employed,Adata9$Income)

corr <- round(cor(Check5), 3)
ggcorrplot(corr, hc.order = TRUE, outline.col = "white")+labs(title = "Employed vs Income")+labs(x="Employed", y="Income" )

#Correlation unemployement vs Income

Check6<- data.frame(Adata9$Unemployment,Adata9$Income)

corr <- round(cor(Check6), 3)
ggcorrplot(corr, hc.order = TRUE, outline.col = "white")+labs(title = "Unemployment vs Income")+labs(x="Unemployment", y="Income" )

#Correlation population vs unemployement

Check7<- data.frame(Adata9$TotalPop,Adata9$Unemployment)

corr <- round(cor(Check7), 3)
ggcorrplot(corr, hc.order = TRUE, outline.col = "white")+labs(title = "Population vs Unemployment")+labs(x="Population", y="Unemployment" )

#Correlation population vs Income

Check8<- data.frame(Adata9$TotalPop,Adata9$Income)

corr <- round(cor(Check8), 3)
ggcorrplot(corr, hc.order = TRUE, outline.col = "white")+labs(title = "Population vs Income")+labs(x="Population", y="Income" )




```


### Chapter 5: Tests
**tests and results**

First, let's start to get a general idea of how poverty relates to all the factors by looking at the correlation matrix between 'Poverty' and the other variables.

```{r sub,echo=FALSE}
library(corrplot)
subset1<-subset(Adata9,select = -c(CensusId,State,County))
crr<-cor(subset1)
corrplot(crr,method = 'number',type = 'upper',number.font = 1, number.cex = 0.5)
```

If we look at the correlation plot, we can see that the variables 'Income','ChildPoverty','Professional','Service','Production', 'WorkAtHome','PublicWork','SelfEmployed', and 'Unemployment' has relevantly high correlation. Therefore, we would like to compute some tests to see if they are truly the factors that affects poverty. 

As long as all the variables listed above are checked to be normality distributed in Chapter 3, we are able to perform tests directly on them. Since the independent variables and the dependent variable 'Poverty' are all quantitative, t-test would be the best choice to test the hypothesis.

We will now perform a two sample t-test to see if the counties with different income have different poverty. To setup, we divide the data into two parts (one with income values above the average income, the other with income values below average income) and take a sample of size 50, we set our $\alpha$ value as 0.05,and our hypothesis as:

$H_0$: $\mu_{upper}=\mu_{lower}$, the two sub-datasets have the same average poverty.
$H_1$: $\mu_{upper}\neq\mu_{lower}$, the two sub-datasets do not have the same average poverty.

```{r income test,echo=FALSE,results='hold'}
set.seed(123)
income_upper<-Adata9[Adata9$Income>mean(Adata9$Income),]
income_lower<-Adata9[Adata9$Income<mean(Adata9$Income),]
iu_sample<-income_upper[sample(nrow(income_upper),50),]
il_sample<-income_lower[sample(nrow(income_lower),50),]
income_ttest<-t.test(iu_sample$Poverty,il_sample$Poverty)
income_ttest
```

Since the p-value we got from the t-test is $2*10^{-16}$ which is smaller than a $\alpha$ value of 0.05, we have sufficient evidence to reject $H_0$ and conclude that there is a difference between the mean poverty for the two groups. Thus, 'poverty' is affected by 'Income'.

```{r professional test,echo=FALSE,results='hold'}
set.seed(123)
prof_upper<-Adata9[Adata9$Professional>mean(Adata9$Professional),]
prof_lower<-Adata9[Adata9$Professional<mean(Adata9$Professional),]
pu_sample<-prof_upper[sample(nrow(prof_upper),50),]
pl_sample<-prof_lower[sample(nrow(prof_lower),50),]
prof_ttest<-t.test(pu_sample$Poverty,pl_sample$Poverty)
prof_ttest
```

P-value for 'Professional' is $2*10^{-4}$ which is less than 0.05, we reject the null and state that 'Professional' is a affecting factor on 'Poverty'.

```{r Service test,echo=FALSE,results='hold'}
set.seed(123)
serv_upper<-Adata9[Adata9$Service>mean(Adata9$Service),]
serv_lower<-Adata9[Adata9$Service<mean(Adata9$Service),]
su_sample<-serv_upper[sample(nrow(serv_upper),50),]
sl_sample<-serv_lower[sample(nrow(serv_lower),50),]
serv_ttest<-t.test(su_sample$Poverty,sl_sample$Poverty)
serv_ttest
```

P-value for 'Service' is 0.004 which is smaller than 0.05, we reject the null and state that 'Service' is an affecting factor for 'Poverty'.

```{r production test,echo=FALSE,results='hold'}
set.seed(123)
prod_upper<-Adata9[Adata9$Production>mean(Adata9$Production),]
prod_lower<-Adata9[Adata9$Production<mean(Adata9$Production),]
produ_sample<-prod_upper[sample(nrow(prod_upper),50),]
prodl_sample<-prod_lower[sample(nrow(prod_lower),50),]
prod_ttest<-t.test(produ_sample$Poverty,prodl_sample$Poverty)
prod_ttest
```

P-value for 'Production' is 0.2 which is greater than 0.05, we can not reject $H_0$, and can not conclude that 'Production' is an affecting factors for 'Poverty'.

```{r WorkAtHome test,echo=FALSE,results='hold'}
set.seed(123)
WAH_upper<-Adata9[Adata9$WorkAtHome>mean(Adata9$WorkAtHome),]
WAH_lower<-Adata9[Adata9$WorkAtHome<mean(Adata9$WorkAtHome),]
wu_sample<-WAH_upper[sample(nrow(WAH_upper),50),]
wl_sample<-WAH_lower[sample(nrow(WAH_lower),50),]
WAH_ttest<-t.test(wu_sample$Poverty,wl_sample$Poverty)
WAH_ttest
```

P-value for "WorkAtHome' is extremely small, we have sufficient evidence to state that "WorkAtHome' is an effecting factor for 'Poverty'.

```{r PublicWork test,echo=FALSE,results='hold'}
set.seed(123)
PW_upper<-Adata9[Adata9$PublicWork>mean(Adata9$PublicWork),]
PW_lower<-Adata9[Adata9$PublicWork<mean(Adata9$PublicWork),]
pubu_sample<-PW_upper[sample(nrow(PW_upper),50),]
publ_sample<-PW_lower[sample(nrow(PW_lower),50),]
PW_ttest<-t.test(pubu_sample$Poverty,publ_sample$Poverty)
PW_ttest
```

P-value for 'PublicWork' is greater than 0.05, so it is not an effecting factor for 'Poverty'.

```{r SelfEmployed test,echo=FALSE,results='hold'}
set.seed(123)
SE_upper<-Adata9[Adata9$SelfEmployed>mean(Adata9$SelfEmployed),]
SE_lower<-Adata9[Adata9$SelfEmployed<mean(Adata9$SelfEmployed),]
semu_sample<-SE_upper[sample(nrow(SE_upper),50),]
seml_sample<-SE_lower[sample(nrow(SE_lower),50),]
SE_ttest<-t.test(semu_sample$Poverty,seml_sample$Poverty)
SE_ttest
```

P-value for 'SelfEmployment' is 0.1 which is greater than 0.05, we can not reject $H_0$,  so it is not an effecting factor for 'Poverty'.

```{r UnEmployment test,echo=FALSE,results='hold'}
set.seed(123)
UE_upper<-Adata9[Adata9$Unemployment>mean(Adata9$Unemployment),]
UE_lower<-Adata9[Adata9$Unemployment<mean(Adata9$Unemployment),]
uemu_sample<-UE_upper[sample(nrow(UE_upper),50),]
ueml_sample<-UE_lower[sample(nrow(UE_lower),50),]
UE_ttest<-t.test(uemu_sample$Poverty,ueml_sample$Poverty)
UE_ttest
```

P-value for 'Unemployment' is $2*10^{-7}$, so we have sufficient evidence to reject null and conclude that it is an effecting factor for 'Poverty'.

Noticing that 'State' is left out from our correlation matrix since it is a categorical variable, we want to perform an ANOVA test to see if there's difference in 'Poverty' across different states.

```{r State ANOVA test,echo=FALSE,results='hold'}
anostate<-aov(Poverty~State,data = Adata9)
summary(anostate)
```

As we can see in the results of ANOVA test, our p-value is extremely small, so we have sufficient evidence to reject the null and conclude that there is difference in 'Poverty' for different states. In this case, 'State' is an effecting factor for 'Poverty'. Finally, we will perform a Post-hoc test to see the pairs of states that have different 'Poverty' as below. We will not display the result here since we not need this information to answer our SMART question, just save it for further analysis if needed.

```{r State Post-hoc test,include=FALSE}
tukeyAoV <- TukeyHSD(anostate)
tukeyAoV
```


### Chapter 6: Conclusion. 


This dataset provided many insights into the dynamics of the US census demographic data. However, we were interested particularly in poverty and what are the factors that affect it. In order to answer our question, we performed data cleansing to prepare our dataset for EDA. Then, we perform normality test for 10 variables (our desired columns) to check if the data normally distributed. This is a necessary step, so we can use the normally distributed variables in tests that required such condition. 

We used graphs and relationship to come up with insights in regard to poverty and we found 
that the major cause of poverty is consistent increase of population with unemployment. 
As these two factors were dominant in Texas state. 

Finally, by doing analysis with correlations, t-tests and ANOVA test, we state that, as a conclusion, the effecting factors for 'Poverty' are 'Income', 'Professional', 'Service', 'WorkAtHome', 'Unemployment', and 'State'.









